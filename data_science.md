# 参考にした資料


小島 寛之, 完全独習 統計学入門 単行本（ソフトカバー）, 2006/9/28
https://mathtrain.jp/
https://ja.wikipedia.org/


# ネイマン・ピアソン統計学とは

記述統計:	得られたデータから特徴を抜き出す技術
推測統計:	確率理論を応用し、全体を把握しきれないほど大きな対象や、未来に起こることを推測する技術
縮約:		データとして並んでいるたくさんの数字を、何かの基準で整理整頓して、意味のある情報だけ抽出すること
統計量:		統計的技術で対象のデータから得られた特徴を表す数値

# ヒストグラム

## 度数分布表

|階級|階級値|度数|相対度数|累積度数|
|---|---|---|---|---|
|141-145|143|1|0.0125|1|
|146-150|148|6|0.075|7|
|151-155|153|19|0.2375|26|
|156-160|158|30|0.375|56|
|161-165|163|18|0.225|74|
|166-170|168|6|0.0725|80|

**階級**：  
おおよそ範囲が最大値ｆから最小値になるような区切りのいい範囲を作り、その範囲を5〜8程度に区切った小区間  
**階級値**：  
各階級を代表する値。一般的には真ん中の値。  
**度数**：  
各階級に入るデータ数。  
**相対度数**：  
各階級の度数の、全体に占める割合。総和が1になる。  
**累積度数**：  
その階級までの度数を合計したもの。  


# 基本的な統計量

平均値 $\mu$ (Mean) $= 階級値 * 相対度数の合計 \\\
\approx データの合計 / データ数$  

偏差 (Deviation) $= データの数値 - 平均値$  

分散 $\sigma^2$ (Variance) $= 偏差の2乗の合計 / データ数 \\\
\approx (階級値 - 平均値)^2 * 相対度数の合計$  

標準偏差 $\sigma$ (Standard Deviation) $= \sqrt{分散} = 偏差の二乗平均$  

>**ちなみに。。。いろいろな平均値**  
>算術平均：
>$\frac{(x+y)}{2}$  
>相乗平均：
>$\sqrt{xy}$  
>二乗平均：
>$\sqrt{\frac{(x^2+y^2)}{2}}$  
>調和平均：
>$\frac{2}{\frac{1}{x}+\frac{1}{y}}$  

# 区間推定

母集団のすべての母数に対して、その母数を仮定したときに観測されるデータの「95パーセント予言的中区間」に現実に観測されたデータが入ることを検証し（検定）、そような母数だけを集める推定の方法。  
区間推定によって定められた母数の範囲を「95パーセント信頼区間」という。

# 仮説検定 (Hypothesis Testing)
正規分布している（あるいは正規分布で近似できる）母集団の母数について、その母数がある数値でである仮説の検証は、次の通りに実行する。  
その母数の母集団が正規分布していて、その平均値を$\mu$、S.D.を$\sigma$としたとき、観測されたデータに対して不等式  

検証したい仮説：帰無仮説
検証したい仮説ではない結論になる仮説：対立仮説

$-1.96 \leq \frac{x-\mu}{\sigma} \leq 1.96$  

が成立するなら、仮説は棄却されない（採択される）。  
成立しないなら、仮説は棄却される。

## 有意水準 $\alpha$

帰無仮説を棄却するかしないかの基準となる確率 $\alpha$。
有意水準を決定する科学的根拠は存在しないが、統計学上では一般に5パーセントか1パーセントと設定される。

## 95パーセント予測区間

95パーセント予測区間$x$は、以下の不等式を解いて得られる。  

$-1.96 \leq \frac{x-\mu}{\sigma} \leq 1.96$  

## 95パーセント信頼区間
さまざまな観測値から同じ方法で区間推定をすると、そのうち95パーセントは正しい母数を含んでいるという区間。


# 母集団と標本と推定値

無限母集団 (Infinite Population)：  
各データは無限個ずつ存在していて、その「観測されやすさ」はそれぞれことなっている。

ランダム・サンプリングの仮定：  
十分な回数の観測を行い、ヒストグラムを作成すると、母集団の分布が再現される。

母集団の平均値$\mu$を母平均といい、以下の方法で求められる。  
$\mu = データの数値 * 相対度数の和$


大数の法則：  
1つの母集団から、$n$個のデータを観測し、その標本平均$\overline{x}$を作る。このとき、$n$が大きければ大きいほど、標本平均は母平均$\mu$に近い値を取る可能性が高くなる。

正規母集団 (Normal Population)：  
正規分布している母集団


正規母集団の母平均 (population mean)を$\mu$、母標準偏差を$\sigma$とするとき、そこから観測されるデータ$x_i$の$n$個に対する標本平均(Sample Mean)$\overline{x}$の分布は、正規表現である。  
$\overline{x}$の分布の平均値は$\mu$のままだが、S.D.は$\frac{\sigma}{\sqrt{n}}$と母集団に比べて$\sqrt{n}$分の1に縮む。

標本数 $n$：  

母平均:  
母集団の平均値  

母分散:  
全体の分布（母集団）の分散。未知数であることが多い。  

標本平均（Sample Mean）:  
標本（データ）の分散。$\frac{1}{n}\sum^{n}_{i=1}(x_i - \overline{x})^2$  

標本分散 $s^2$（Sample Variance）：

不偏分散:  
母分散の不偏推定量。標本分散を$\frac{n}{n-1}$したもの。$\frac{1}{n-1}\sum^{n}_{i=1}(x_i - \overline{x})^2$


# z検定

正規分布を用いる統計学的検定法で、標本の平均と母集団の平均とが統計学的にみて有意に異なるかどうかを検定する方法である。

次の数値が既知であるとする

* σ（母集団の標準偏差）
* μ（母集団の平均）
* x （標本の平均）
* n （標本サイズ）



## 標準正規分布 (Standard Normal Distribution)

$f(x) = \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}x^2}$

### 標準正規分布の特徴

#### 正規分布の観測値の平均の性質

平均$\mu$、標準偏差$\sigma$の正規分布に従って観測される数値を、$n$個観測し、その平均値を$\overline{x}$と記す。すなわち  

$\overline{x} = (n個の観測値の和) / n$

このとき、$\overline{x}$も正規分布に従い、その平均と標準偏差は、  

平均$\mu$、標準偏差$\frac{\sigma}{\sqrt{n}}$

で与えられる。



標準正規分布において  
**(-1.96)~(+1.96)の範囲のデータの相対度数は0.95（95％）**  

>ちなみに、  
(-1)~(+1)の範囲のデータの相対度数は0.6826（約70％）  
(-2)~(+2)の範囲のデータの相対度数は0.9544（約95％）  

標準正規分布のデータを$z$とすると、  
一般正規分布のデータ$x$は  

$x = \sigma * z + \mu$  

で得られ、  

$平均値 = \mu, S.D. = \sigma$  

である。

よって、  
平均値が$\mu$、S.D.が$\sigma$の正規分布においては、

**$(\mu-1.96\sigma)~(\mu+1.96\sigma)$の範囲のデータの相対度数は0.95（95％）**  


# カイ二乗検定 (Chi-squared Test)

## カイ二乗分布 (Chi-squared distribution)

## 標本分散 $V$
母平均$\mu$、母標準偏差$\sigma$の正規母集団から$n$個の標本$x_1, x_2, ... x_n$を観測し、  

$V = (\frac{x\_1-\mu}{\sigma})^2 + (\frac{x\_2-\mu}{\sigma})^2 + ... + (\frac{x\_n-\mu}{\sigma})^2$

という$V$を計算すると、$V$は自由度$n$のカイ二乗分布をする。



## 不偏分散 $W$
母平均$\mu$、母標準偏差$\sigma$の正規母集団から$n$個の標本$x_1, x_2, ... x_n$を観測し、  

$W = (\frac{x\_1-\overline{x}}{\sigma})^2 + (\frac{x\_2-\overline{x}}{\sigma})^2 + ... + (\frac{x\_n-\overline{x}}{\sigma})^2$

という$W$を計算すると、$V$は自由度$n-1$のカイ二乗分布をする。

$n \times s^2 = \sigma^2 \times W$


**補論**
なぜ$W$が$V$より自由度が1だけ下がるのか？  


### 95パーセント予言的中区間

# t-検定 (Student's t-test)

## t-分布 (t-distribution)

**定義**  

$T = \frac{z\sqrt{k}}{\sqrt{W}} \\\
= \frac{(標準正規分布のデータz) \times \sqrt{Wの自由度k}}{\sqrt{カイ二乗分布W}}$



# ベイズ統計学とは

事前確率:  

事前分布:  

推測の改定:  

事後確率（ベイズ逆確率）:  

ベイズ更新:  

ベイズ推定:  
事前確率を行動の観察によって、事後確率へとベイズ更新すること

主観確率:  
「人が心に思い描く数値」と解釈する確率


## 理由不十分の原則

## 最尤原理


# 確率

素事象$e$について、その確率は$p({e})$と記す。

$p({e, f, g}) = p({e}) + p({f}) + p({g})$

**加法法則**  

$p(A or B) = p(A) + p(B)$

**乗法法則**  

$p(A \& B) = p(A) \times p(B)$


**条件付き確率**  

事象$B$という情報を得た下での事象$A$の条件付き確率$p(A|B)$は、以下の式で定義される。

$p(A \mid B) = p(A \& B) / p(B)$


**確率分布**  

**確率密度**  

**期待値**  

# ベータ分布

$y = (定数) \times x^{\alpha -1} (1-x)^{\beta -1}$


**ベータ分布の期待値**  

$\frac{\alpha}{\alpha + \beta}$





